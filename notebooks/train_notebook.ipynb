{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CNN Image Classifier Training\n",
    "\n",
    "\n",
    "\n",
    " This notebook implements training for an improved CNN model on image classification tasks. Features include:\n",
    "\n",
    " - CIFAR-10/100 dataset support\n",
    "\n",
    " - Automatic Mixed Precision (AMP) training\n",
    "\n",
    " - Learning rate scheduling with OneCycleLR\n",
    "\n",
    " - Early stopping and model checkpointing\n",
    "\n",
    " - Training visualization\n",
    "\n",
    " - GPU acceleration\n",
    "\n",
    " - Reproducible results with fixed seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Project Structure\n",
    "\n",
    "\n",
    "\n",
    " ```\n",
    "\n",
    " cnn-image-classifier/\n",
    "\n",
    " ├── datasets/           # Dataset handling\n",
    "\n",
    " │   └── dataset.py     # Data loading and preprocessing\n",
    "\n",
    " ├── models/            # Model architectures\n",
    "\n",
    " │   └── cnn_model.py   # CNN implementation\n",
    "\n",
    " ├── training/          # Training scripts\n",
    "\n",
    " │   └── train.py       # Main training script\n",
    "\n",
    " ├── notebooks/         # Jupyter notebooks\n",
    "\n",
    " │   └── train_notebook.py  # This notebook\n",
    "\n",
    " ├── checkpoints/       # Saved models\n",
    "\n",
    " ├── data/             # Dataset storage\n",
    "\n",
    " └── requirements.txt   # Dependencies\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def setup_environment():\n",
    "    \"\"\"Setup the training environment including package installation and seeds.\"\"\"\n",
    "    import sys\n",
    "    import subprocess\n",
    "    \n",
    "    # Install required packages if not present\n",
    "    required_packages = [\n",
    "        'torch',\n",
    "        'torchvision',\n",
    "        'tqdm',\n",
    "        'matplotlib'\n",
    "    ]\n",
    "    \n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(SEED)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    print(\"Environment setup completed!\")\n",
    "    print(f\"Random seed set to: {SEED}\")\n",
    "\n",
    "# Run setup\n",
    "setup_environment()\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Import Local Modules\n",
    "\n",
    " First, make sure you're in the correct directory and the repository is properly set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import local modules\n",
    "from datasets.dataset import get_data_loaders\n",
    "from models.cnn_model import ImprovedCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Training Configuration\n",
    "\n",
    "\n",
    "\n",
    " Adjust these parameters based on your needs:\n",
    "\n",
    " - `epochs`: Number of training epochs\n",
    "\n",
    " - `batch_size`: Batch size for training\n",
    "\n",
    " - `learning_rate`: Initial learning rate\n",
    "\n",
    " - `dataset`: Choose between 'cifar10' or 'cifar100'\n",
    "\n",
    " - `model_size`: Choose between 'small', 'medium', or 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "config = {\n",
    "    'epochs': 100,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.1,\n",
    "    'weight_decay': 5e-4,\n",
    "    'dataset': 'cifar10',  # or 'cifar100'\n",
    "    'model_size': 'medium',  # 'small', 'medium', or 'large'\n",
    "    'data_dir': '../data',\n",
    "    'save_dir': '../checkpoints',\n",
    "    'early_stopping_patience': 10,\n",
    "    'use_amp': True  # Automatic Mixed Precision\n",
    "}\n",
    "\n",
    "# Print configuration\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def train_model(config):\n",
    "    \"\"\"\n",
    "    Main training function that handles:\n",
    "    - Model creation and training\n",
    "    - Data loading\n",
    "    - Optimization\n",
    "    - Checkpointing\n",
    "    - Early stopping\n",
    "    - Training visualization\n",
    "    \"\"\"\n",
    "    # Create save directory\n",
    "    save_dir = Path(config['save_dir'])\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save configuration\n",
    "    run_id = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    with open(save_dir / f'config_{run_id}.json', 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(\n",
    "        dataset_name=config['dataset'],\n",
    "        data_dir=config['data_dir'],\n",
    "        batch_size=config['batch_size']\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = ImprovedCNN({\n",
    "        'input_channels': 3,\n",
    "        'num_classes': 10 if config['dataset'] == 'cifar10' else 100,\n",
    "        'model_size': config['model_size'],\n",
    "        'dropout_rate': 0.5\n",
    "    }).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        momentum=0.9,\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=config['learning_rate'],\n",
    "        epochs=config['epochs'],\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,\n",
    "        final_div_factor=1e4\n",
    "    )\n",
    "    \n",
    "    # Automatic Mixed Precision\n",
    "    scaler = GradScaler('cuda') if config['use_amp'] else None\n",
    "    \n",
    "    # Training metrics\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = AverageMeter()\n",
    "        train_acc = AverageMeter()\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} - Training\")\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if config['use_amp']:\n",
    "                with autocast('cuda'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct = predicted.eq(labels).sum().item()\n",
    "            \n",
    "            train_loss.update(loss.item(), inputs.size(0))\n",
    "            train_acc.update(correct / inputs.size(0), inputs.size(0))\n",
    "            \n",
    "            # Step the scheduler after optimizer step\n",
    "            if epoch > 0 or batch_idx > 0:  # Skip the very first step\n",
    "                scheduler.step()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{train_loss.avg:.4f}\",\n",
    "                'acc': f\"{train_acc.avg*100:.2f}%\"\n",
    "            })\n",
    "        \n",
    "        train_losses.append(train_loss.avg)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = AverageMeter()\n",
    "        val_acc = AverageMeter()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                correct = predicted.eq(labels).sum().item()\n",
    "                \n",
    "                val_loss.update(loss.item(), inputs.size(0))\n",
    "                val_acc.update(correct / inputs.size(0), inputs.size(0))\n",
    "        \n",
    "        val_accuracies.append(val_acc.avg)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}\")\n",
    "        print(f\"Train Loss: {train_loss.avg:.4f}, Train Acc: {train_acc.avg*100:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss.avg:.4f}, Val Acc: {val_acc.avg*100:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc.avg > best_val_acc:\n",
    "            best_val_acc = val_acc.avg\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'config': config\n",
    "            }, save_dir / f'best_model_{run_id}.pth')\n",
    "            print(f\"✅ Saved new best model with validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= config['early_stopping_patience']:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot([x * 100 for x in val_accuracies])\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / f'training_curves_{run_id}.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Final evaluation on test set\n",
    "    model.eval()\n",
    "    test_acc = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct = predicted.eq(labels).sum().item()\n",
    "            test_acc.update(correct / inputs.size(0), inputs.size(0))\n",
    "    \n",
    "    print(f\"\\nFinal Test Accuracy: {test_acc.avg*100:.2f}%\")\n",
    "    \n",
    "    # Save final results\n",
    "    results = {\n",
    "        'best_val_acc': float(best_val_acc),\n",
    "        'final_test_acc': float(test_acc.avg),\n",
    "        'total_epochs': epoch + 1\n",
    "    }\n",
    "    \n",
    "    with open(save_dir / f'results_{run_id}.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Run Training\n",
    "\n",
    "\n",
    "\n",
    " Before running the training:\n",
    "\n",
    " 1. Make sure you're using a GPU runtime (if available)\n",
    "\n",
    " 2. Verify the configuration parameters above\n",
    "\n",
    " 3. Ensure you have enough disk space for checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    # Run training\n",
    "    model, results = train_model(config)\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(f\"Best validation accuracy: {results['best_val_acc']*100:.2f}%\")\n",
    "    print(f\"Final test accuracy: {results['final_test_acc']*100:.2f}%\")\n",
    "    print(f\"Total epochs: {results['total_epochs']}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
